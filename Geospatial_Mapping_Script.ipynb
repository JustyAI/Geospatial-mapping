{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9b2b52-b629-4901-a26d-b38ae45fd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, MultiLineString, LineString\n",
    "import xml.etree.ElementTree as ET\n",
    "import pyproj\n",
    "import re\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union, nearest_points, substring\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, MultiLineString, LineString\n",
    "import xml.etree.ElementTree as ET\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825fcb3-e9a8-47c3-b215-67d0f324c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data, convert format (XML to Geopandas Dataframe; CSV to Geopandas Dataframe), Geospatial reference alignment, snapping process and divide the resulting dataframe into segments (e.g., the bus stop-to-stop segemnt here)\n",
    "\n",
    "def process_bus_route_mass_conversion(input_directory='Route_Geometry', output_directory='Route_Geometry_GeoJSON', stops_directory='stops', stops_output_directory='Stops_GeoJSON'):\n",
    "    # Task 1: Read xml and handle it in geojson with corresponding conversion\n",
    "    # Loop through all date directories in the input directory\n",
    "    for date_folder in os.listdir(input_directory):\n",
    "        date_path = os.path.join(input_directory, date_folder)\n",
    "        \n",
    "        # Check if the date_path is a directory\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "        \n",
    "        # Extract date from the folder name\n",
    "        date_str = date_folder.split('_')[-1]\n",
    "\n",
    "        # Loop through each route XML file within the date directory\n",
    "        for file_name in os.listdir(date_path):\n",
    "            if file_name.endswith('.xml'):\n",
    "                route_path = os.path.join(date_path, file_name)\n",
    "\n",
    "                # Extract route number and date from file name\n",
    "                route_str = file_name.split('_')[2]  # assuming file name format is Route_Geometry_{route}_{date}.xml\n",
    "\n",
    "                # Load and clean XML content\n",
    "                with open(route_path, 'r', encoding='utf-8') as file:\n",
    "                    xml_content = file.read()\n",
    "                xml_content_no_ns = re.sub(r'xmlns(:\\w+)?=\"[^\"]+\"', '', xml_content)\n",
    "                xml_content_no_ns = re.sub(r'\\b\\w+:', '', xml_content_no_ns)\n",
    "                root = ET.fromstring(xml_content_no_ns)\n",
    "\n",
    "                # Extract data from XML and add to list\n",
    "                data = []\n",
    "                for route in root.findall('.//Route_Geometry'):\n",
    "                    row = {\n",
    "                        'Contract_Line_No': route.attrib.get('aContract_Line_No'),\n",
    "                        'LBSL_Run_No': route.attrib.get('aLBSL_Run_No'),\n",
    "                        'Sequence_No': route.attrib.get('aSequence_No'),\n",
    "                        'Direction': route.find('Direction').text if route.find('Direction') is not None else None,\n",
    "                        'Location_Easting': route.find('Location_Easting').text if route.find('Location_Easting') is not None else None,\n",
    "                        'Location_Northing': route.find('Location_Northing').text if route.find('Location_Northing') is not None else None,\n",
    "                        'Location_Longitude': route.find('Location_Longitude').text if route.find('Location_Longitude') is not None else None,\n",
    "                        'Location_Latitude': route.find('Location_Latitude').text if route.find('Location_Latitude') is not None else None,\n",
    "                        'Date': date_str,  # Add date column\n",
    "                        'Route': route_str  # Add route column\n",
    "                    }\n",
    "                    data.append(row)\n",
    "\n",
    "                # Create DataFrame and check for missing columns\n",
    "                df = pd.DataFrame(data)\n",
    "                expected_columns = ['Location_Easting', 'Location_Northing', 'Location_Longitude', 'Location_Latitude']\n",
    "                for col in expected_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = None  # Add missing columns as None if they donâ€™t exist\n",
    "\n",
    "                # Convert numeric columns\n",
    "                df[expected_columns] = df[expected_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "                # Convert df to GeoDataFrame\n",
    "                df['geometry'] = df.apply(lambda row: Point(row['Location_Longitude'], row['Location_Latitude']) if pd.notnull(row['Location_Longitude']) and pd.notnull(row['Location_Latitude']) else None, axis=1)\n",
    "                gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "                gdf.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "                # Remove rows with missing geometry\n",
    "                gdf = gdf[gdf['geometry'].notna()]\n",
    "                \n",
    "                print(file_name)\n",
    "                \n",
    "                # Ensure 'Direction' column exists before grouping\n",
    "                if 'Direction' not in gdf.columns:\n",
    "                    print(f\"No 'Direction' column found in {file_name}. Skipping this file...\")\n",
    "                    continue\n",
    "                    \n",
    "                # Filter rows where Direction is the same as LBSL_Run_No\n",
    "                gdf = gdf[gdf['Direction'] == gdf['LBSL_Run_No']]\n",
    "\n",
    "                # Group by Direction and create MultiLineString for each group\n",
    "                multilines = []\n",
    "                for direction, group in gdf.groupby('Direction'):\n",
    "                    \n",
    "                    # Extract coordinates as a list of tuples (longitude, latitude)\n",
    "                    coords_direction = list(group.apply(lambda row: (row['Location_Longitude'], row['Location_Latitude']), axis=1))\n",
    "\n",
    "                    # Create a LineString geometry from the coordinates\n",
    "                    line_direction = LineString(coords_direction)\n",
    "\n",
    "                    # Append to the multilines list\n",
    "                    multilines.append({\n",
    "                        'Direction': direction,\n",
    "                        'geometry': line_direction\n",
    "                    })\n",
    "                                    \n",
    "                # Create GeoDataFrame for MultiLineString geometries\n",
    "                multilines_gdf = gpd.GeoDataFrame(multilines, geometry='geometry', crs=\"EPSG:4326\")\n",
    "                #multilines_gdf.set_crs(epsg=4326, inplace=True)\n",
    "                multilines_gdf['Direction'] = multilines_gdf['Direction'].astype(int)\n",
    "                \n",
    "                #print(multilines_gdf)\n",
    "                \n",
    "                # Task 2: Process stops file\n",
    "                stops_file_path = os.path.join(stops_directory, f'Data_3rdParties_bus-sequences-{date_str}.csv')\n",
    "                if os.path.exists(stops_file_path):\n",
    "                    stops_df = pd.read_csv(stops_file_path)\n",
    "\n",
    "                    # Filter stops DataFrame by Route\n",
    "                    stops_df = stops_df[stops_df['Route'] == route_str]\n",
    "                    \n",
    "                    # Skip this route if no stops data is available for it\n",
    "                    if stops_df.empty:\n",
    "                        print(f\"No stops data found for route {route_str}. Skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Define the input (OSGB36 / British National Grid) and output coordinate reference system (WGS84)\n",
    "                    transformer = pyproj.Transformer.from_crs(\"EPSG:27700\", \"EPSG:4326\", always_xy=True)\n",
    "                    # Step 1: Apply the transformer to convert easting and northing to longitude and latitude\n",
    "                    stops_df[['Longitude', 'Latitude']] = stops_df.apply(lambda row: pd.Series(transformer.transform(row['Location_Easting'], row['Location_Northing'])), axis=1)\n",
    "                \n",
    "                    # Step 2: Create a new column called 'geometry' using the longitude and latitude columns\n",
    "                    stops_df['geometry'] = stops_df.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
    "\n",
    "                    # Step 3: Convert the DataFrame to a GeoDataFrame\n",
    "                    stops_gdf = gpd.GeoDataFrame(stops_df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "                    stops_gdf = stops_gdf.reset_index()\n",
    "                    stops_gdf = stops_gdf.drop(columns = ['index'])\n",
    "                    \n",
    "                    # Step 4: Add info of required columns\n",
    "                    # Create columns for 'from_stop_Name' and 'to_stop_Name'\n",
    "                    stops_gdf['from_stop_Name'] = stops_gdf['Stop_Name']\n",
    "                    stops_gdf['to_stop_Name'] = stops_gdf['Stop_Name'].shift(-1)\n",
    "                    # Create columns for 'from_stop_code' and 'to_stop_code'\n",
    "                    stops_gdf['from_stop_code'] = stops_gdf['Stop_Code_LBSL']\n",
    "                    stops_gdf['to_stop_code'] = stops_gdf['Stop_Code_LBSL'].shift(-1)\n",
    "                    # Create columns for 'sequence_from_stop' and 'sequence_to_stop'\n",
    "                    stops_gdf['sequence_from_stop'] = stops_gdf['Sequence']\n",
    "                    stops_gdf['sequence_to_stop'] = stops_gdf['Sequence'].shift(-1)\n",
    "                    stops_gdf.sequence_to_stop = stops_gdf.sequence_to_stop.fillna(-99)\n",
    "                    stops_gdf['sequence_to_stop'] = stops_gdf['sequence_to_stop'].astype(int)\n",
    "                    stops_gdf['Run'] = stops_gdf['Run'].astype(int)\n",
    "                    \n",
    "                # Task 3: Snap stops to corresponding route geometry\n",
    "                for direction in multilines_gdf['Direction'].unique():\n",
    "                    direction = int(direction)\n",
    "                    route_gdf_direction = multilines_gdf[multilines_gdf['Direction'] == direction]\n",
    "                    stops_gdf_direction = stops_gdf[stops_gdf['Run'] == direction]\n",
    "\n",
    "                    # Skip if no stops data exists for this direction\n",
    "                    if route_gdf_direction.empty or stops_gdf_direction.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Combine all geometries in 'geometry' column into a single MultiLineString\n",
    "                    route = unary_union(route_gdf_direction['geometry'].tolist())                        \n",
    "                        \n",
    "                    # Check if route was successfully created\n",
    "                    if route.is_empty:\n",
    "                        print(f\"Route geometry for route {route_str} direction {direction} is empty. Skipping...\")\n",
    "                        continue\n",
    "                        \n",
    "                    # Convert MultiLineString to LineString if necessary\n",
    "                    if isinstance(route, MultiLineString):\n",
    "                        # Merge the MultiLineString into a single LineString\n",
    "                        route = LineString([point for line in route for point in line.coords])\n",
    "\n",
    "                    # Snap each stop to the nearest point on the route\n",
    "                    def snap_to_route(stop):\n",
    "                        # Check if stop is a valid geometry\n",
    "                        if stop is None or stop.is_empty:\n",
    "                            return None\n",
    "                        # Calculate nearest point only if stop and route are valid\n",
    "                        nearest_point = nearest_points(route, stop)[0]\n",
    "                        return nearest_point\n",
    "\n",
    "                    # Apply snapping to get the nearest point on the route for each stop\n",
    "                    stops_gdf_direction['snapped'] = stops_gdf_direction.geometry.apply(snap_to_route)\n",
    "\n",
    "                    # Calculate the distance along the route for each stop\n",
    "                    def distance_along_route(stop):\n",
    "                        if stop is None or stop.is_empty:\n",
    "                            return None\n",
    "                        return route.project(stop)\n",
    "                    \n",
    "                    # Distance from the first point on the route\n",
    "                    stops_gdf_direction['stop_distance_from_1st'] = stops_gdf_direction['snapped'].apply(distance_along_route)\n",
    "\n",
    "                    # Function to create route geometry between consecutive stops\n",
    "                    def get_segment_geometry(row):\n",
    "                        next_row_index = row.name + 1\n",
    "                        if next_row_index not in stops_gdf_direction.index:  # Last row check\n",
    "                            return None\n",
    "\n",
    "                        # Start and end distances along the route for the segment\n",
    "                        start_distance = row['stop_distance_from_1st']\n",
    "                        end_distance = stops_gdf_direction.loc[next_row_index, 'stop_distance_from_1st']\n",
    "\n",
    "                        # Check and log invalid distances for debugging\n",
    "                        if start_distance is None or end_distance is None:\n",
    "                            print(f\"Missing distance for row {row.name}\")\n",
    "                            return None\n",
    "\n",
    "                        # Ensure valid order for distances\n",
    "                        if start_distance >= end_distance:\n",
    "                            print(f\"Reversed or identical distances at row {row.name}: start_distance={start_distance}, end_distance={end_distance}\")\n",
    "                            return None\n",
    "\n",
    "                        # If route is a MultiLineString, apply substring separately for each LineString part\n",
    "                        if isinstance(route, MultiLineString):\n",
    "                            segments = [substring(line, start_distance, end_distance) for line in route.geoms if line.length >= end_distance - start_distance]\n",
    "                            segment = segments[0] if segments else None\n",
    "                        else:\n",
    "                            # Use substring directly if route is already a LineString\n",
    "                            segment = substring(route, start_distance, end_distance)\n",
    "\n",
    "                        return segment\n",
    "\n",
    "                    # Drop snapped column\n",
    "                    stops_gdf_direction = stops_gdf_direction.drop(columns = ['snapped'])\n",
    "                    \n",
    "                    # Apply the function to each row to create precise segment geometries\n",
    "                    stops_gdf_direction['geometry'] = stops_gdf_direction.apply(get_segment_geometry, axis=1)\n",
    "                    \n",
    "                    # Drop unnecessary column\n",
    "                    stops_gdf_direction = stops_gdf_direction.drop(columns = ['stop_distance_from_1st'])\n",
    "                    \n",
    "                    # Create output path and save as GeoJSON\n",
    "                    output_path = os.path.join(output_directory, date_folder, route_str, str(direction))\n",
    "                    os.makedirs(output_path, exist_ok=True)\n",
    "                    output_file = os.path.join(output_path, f'{file_name.replace(\".xml\", \".geojson\")}')\n",
    "                    stops_gdf_direction.to_file(output_file, driver='GeoJSON')\n",
    "                    print(f'Saved GeoJSON: {output_file}')\n",
    "                \n",
    "                \n",
    "# Run the function\n",
    "process_bus_route_mass_conversion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fbedc-cd7a-4229-b70a-253e053f59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking of output (No point geometry should be returned)\n",
    "\n",
    "def check_geojson_files(directory):\n",
    "    files_checked = 0\n",
    "    point_files = []\n",
    "\n",
    "    # Confirm that the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory not found: {directory}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Scanning directory: {directory}\")\n",
    "\n",
    "    # Traverse through the given directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        print(f\"Entering directory: {root}\")  # Debug: Show current directory\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.geojson'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Checking file: {file_path}\")  # Debug: Show file being checked\n",
    "                \n",
    "                try:\n",
    "                    # Load the GeoJSON file using geopandas\n",
    "                    gdf = gpd.read_file(file_path)\n",
    "                    \n",
    "                    # Check if the geometry type is Point\n",
    "                    if gdf.geometry.geom_type.eq('Point').any():\n",
    "                        point_files.append(file_path)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                \n",
    "                files_checked += 1\n",
    "\n",
    "    # Reporting results\n",
    "    if files_checked == 0:\n",
    "        print(\"\\nNo GeoJSON files found in the directory.\")\n",
    "    elif point_files:\n",
    "        print(\"\\nFiles with Point geometry found:\")\n",
    "        for point_file in point_files:\n",
    "            print(point_file)\n",
    "    else:\n",
    "        print(\"\\nNo files with Point geometry found.\")\n",
    "    \n",
    "    print(f\"\\nTotal files checked: {files_checked}\")\n",
    "\n",
    "# Directory path\n",
    "directory = \"Route_Geometry_GeoJSON/Route_Geometry_20231208\"\n",
    "check_geojson_files(directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
